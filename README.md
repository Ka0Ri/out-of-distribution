# out-of-distribution

## Realiability diagram [1]
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/re.png)
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/scaling.png)
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/label.png)

## Gaussian discriminator and confidence score [2]
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/score.png)
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/hist.png)
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/conf.png)

## Confidence loss [3]
![alt text](https://github.com/Ka0Ri/out-of-distribution/blob/master/img/cf1.png)
## Refererences
[1] Guo, Chuan, et al. "On calibration of modern neural networks." Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017. <br />
[2] Lee, Kimin, et al. "A simple unified framework for detecting out-of-distribution samples and adversarial attacks." Advances in Neural Information Processing Systems. 2018. <br />
[3] Lee, Kimin, et al. "Training confidence-calibrated classifiers for detecting out-of-distribution samples." arXiv preprint arXiv:1711.09325 (2017).
